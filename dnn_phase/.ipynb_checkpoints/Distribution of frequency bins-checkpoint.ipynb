{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook explores the figure 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I 2019-03-18 17:48:45 dataset:1127 found 2 files\n",
      "I 2019-03-18 17:48:46 dataset:1141 iteration size 341\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from scipy.signal import blackmanharris, gaussian\n",
    "import os\n",
    "import theano.tensor as T\n",
    "from theano.sandbox.rng_mrg import MRG_RandomStreams as RandomStreams\n",
    "import theano\n",
    "import lasagne\n",
    "from lasagne.layers import ReshapeLayer,Layer\n",
    "from lasagne.init import Normal\n",
    "from lasagne.regularization import regularize_layer_params_weighted, l2, l1\n",
    "from lasagne.regularization import regularize_layer_params\n",
    "import convsep.util as util\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "from convsep.dataset import LargeDatasetMulti\n",
    "from trainDNN import build_ca, train_auto\n",
    "from phase_transform import PhaseTransform\n",
    "\n",
    "\n",
    "import keras as K\n",
    "\n",
    "# Loading the features\n",
    "# Those were computed using compute_features.py\n",
    "# And stored in \"results/features\"\n",
    "ld2 = LargeDatasetMulti(path_transform_in=\"results/features\", nsources=4,\n",
    "                    batch_size=2, batch_memory=8,\n",
    "                    time_context=11, overlap=75, nprocs=4,\n",
    "                    mult_factor_in=0.3, mult_factor_out=0.3,\n",
    "                    extra_features=True, model=\"p\")\n",
    "ld2.extra_feat_size = 1025\n",
    "\n",
    "# The transformation done when computing the features\n",
    "tt = PhaseTransform(frameSize=2048, hopSize=512, sampleRate=44100, window=gaussian, std=0.4)\n",
    "\n",
    "# db = \"../DSD100_subset/\"\"\n",
    "# testdir = os.path.join(db,'Mixtures')\n",
    "# transform = tt\n",
    "\n",
    "outdir = os.path.join('results','output')\n",
    "model = os.path.join('results','models',\"dnn\")\n",
    "num_epochs = 10\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nchannels:  2\n",
      "nsources:  4\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# train_errs = train_auto(train=ld2, fun=build_ca, transform=tt,\n",
    "#                 outdir=os.path.join(db,'output',model),\n",
    "#                 testdir=os.path.join(db,'Mixtures'),\n",
    "#                 model=os.path.join(db,'models',\"model_\"+model+\".pkl\"),\n",
    "#                 num_epochs=nepochs,\n",
    "#                 scale_factor=scale_factor)\n",
    "\n",
    "fun = build_ca\n",
    "train = ld2\n",
    "\n",
    "\n",
    "sources = ['vocals','bass','drums','other']\n",
    "\n",
    "nchannels = int(train.channels_in)\n",
    "nsources = int(train.channels_out/train.channels_in)\n",
    "\n",
    "print('nchannels: ', nchannels)\n",
    "print('nsources: ', nsources)\n",
    "\n",
    "input_size = int(float(transform.frameSize) / 2 + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Concatenate, Dense, LSTM, Input, concatenate\n",
    "from keras.optimizers import Adagrad\n",
    "import keras.backend as K\n",
    "\n",
    "\n",
    "def build_model(feat_size=1025, nchannels=2, nsources=4):\n",
    "    mag_in = Input(shape=(, ))\n",
    " = Dense(1, )(mag_in)\n",
    "\n",
    "#K.bias_add(x, bias, data_format=None)\n",
    "\n",
    "initial_value = 1\n",
    "learned = tf.Variable(initial_value, name='learned_scalar')\n",
    "Lambda(lambda x: x * learned)\n",
    "\n",
    "second_input = Input(shape=(2, ))\n",
    "second_dense = Dense(1, )(second_input)\n",
    "\n",
    "merge_one = concatenate([first_dense, second_dense])\n",
    "\n",
    "third_input = Input(shape=(1, ))\n",
    "merge_two = concatenate([merge_one, third_input])\n",
    "\n",
    "model = Model(inputs=[first_input, second_input, third_input], outputs=merge_two)\n",
    "model.compile(optimizer=ada_grad, loss='mse',\n",
    "               metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'amp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-c5e2140b204b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0md_out\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m network = build_ca(amp=amp, df_ph=df_ph, dt_ph=dt_ph,\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtime_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         feat_size=1025, nchannels=nchannels, nsources=nsources)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'amp' is not defined"
     ]
    }
   ],
   "source": [
    "def build_ca(amp=None, df_ph=None, dt_ph=None, batch_size=8, time_context=5, feat_size=1025, nchannels=2, nsources=4):\n",
    "\n",
    "    input_shape=(batch_size, nchannels, time_context, feat_size)\n",
    "    n_hiddens = 500\n",
    "    out_shape = (batch_size, nchannels*nsources, feat_size)\n",
    "    print(input_shape)\n",
    "    print(out_shape)\n",
    "    # input layer for amplitude features\n",
    "    a_in = lasagne.layers.FlattenLayer(lasagne.layers.InputLayer(shape=input_shape, input_var=amp))\n",
    "    b_in = lasagne.layers.FlattenLayer(lasagne.layers.InputLayer(shape=input_shape, input_var=df_ph))\n",
    "    c_in = lasagne.layers.FlattenLayer(lasagne.layers.InputLayer(shape=input_shape, input_var=dt_ph))\n",
    "    \n",
    "    d = lasagne.layers.ConcatLayer([a_in, b_in, c_in])\n",
    "    \n",
    "    # DEBUG\n",
    "    d = lasagne.layers.DenseLayer(d, nchannels*nsources*feat_size,\n",
    "                                    nonlinearity=lasagne.nonlinearities.rectify)\n",
    "    d_out = lasagne.layers.ReshapeLayer(d, (out_shape))\n",
    "    return d_out\n",
    "\n",
    "network = build_ca(amp=amp, df_ph=df_ph, dt_ph=dt_ph,\n",
    "        batch_size=2,time_context=5,\n",
    "        feat_size=1025, nchannels=nchannels, nsources=nsources)\n",
    "\n",
    "prediction = lasagne.layers.get_output(network, deterministic=True)\n",
    "\n",
    "sourceall=[]\n",
    "errors_insts = []\n",
    "loss = 0\n",
    "\n",
    "sep_chann = []\n",
    "\n",
    "loss = lasagne.objectives.squared_error(prediction, abs(target_var[:,:,5,:]))\n",
    "loss = loss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time \n",
    "\n",
    "params1 = lasagne.layers.get_all_params(network, trainable=True)\n",
    "updates = lasagne.updates.adadelta(loss, params1)\n",
    "\n",
    "losser=[]\n",
    "\n",
    "train_fn = theano.function([amp, df_ph, dt_ph, target_var], loss, updates=updates, allow_input_downcast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ph.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 2, 11, 1025) (2, 2, 11, 1025) (2, 2, 11, 1025) (2, 8, 11, 1025)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Shape mismatch: x has 67650 cols (and 2 rows) but y has 30750 rows (and 8200 cols)\nApply node that caused the error: Dot22(Join.0, W)\nToposort index: 16\nInputs types: [TensorType(float32, matrix), TensorType(float32, matrix)]\nInputs shapes: [(2, 67650), (30750, 8200)]\nInputs strides: [(270600, 4), (32800, 4)]\nInputs values: ['not shown', 'not shown']\nInputs type_num: [11, 11]\nOutputs clients: [[Elemwise{Add}[(0, 0)](Dot22.0, InplaceDimShuffle{x,0}.0)]]\n\nBacktrace when the node is created(use Theano flag traceback.limit=N to make it longer):\n  File \"/home/pierre-louis/.pyenv/versions/3.5.6/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2869, in _run_cell\n    return runner(coro)\n  File \"/home/pierre-louis/.pyenv/versions/3.5.6/lib/python3.5/site-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/home/pierre-louis/.pyenv/versions/3.5.6/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 3044, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/pierre-louis/.pyenv/versions/3.5.6/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 3209, in run_ast_nodes\n    if (yield from self.run_code(code, result)):\n  File \"/home/pierre-louis/.pyenv/versions/3.5.6/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 3291, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-3-41a522242940>\", line 24, in <module>\n    prediction = lasagne.layers.get_output(network, deterministic=True)\n  File \"/home/pierre-louis/.pyenv/versions/3.5.6/lib/python3.5/site-packages/lasagne/layers/helper.py\", line 197, in get_output\n    all_outputs[layer] = layer.get_output_for(layer_inputs, **kwargs)\n  File \"/home/pierre-louis/.pyenv/versions/3.5.6/lib/python3.5/site-packages/lasagne/layers/dense.py\", line 121, in get_output_for\n    activation = T.dot(input, self.W)\n\nDebugprint of the apply node: \nDot22 [id A] <TensorType(float32, matrix)> ''   \n |Join [id B] <TensorType(float32, matrix)> ''   \n | |TensorConstant{1} [id C] <TensorType(int8, scalar)>\n | |Reshape{2} [id D] <TensorType(float32, matrix)> ''   \n | | |amp [id E] <TensorType(float32, 4D)>\n | | |MakeVector{dtype='int64'} [id F] <TensorType(int64, vector)> ''   \n | |   |Shape_i{0} [id G] <TensorType(int64, scalar)> ''   \n | |   | |amp [id E] <TensorType(float32, 4D)>\n | |   |TensorConstant{-1} [id H] <TensorType(int64, scalar)>\n | |Reshape{2} [id I] <TensorType(float32, matrix)> ''   \n | | |df_ph [id J] <TensorType(float32, 4D)>\n | | |MakeVector{dtype='int64'} [id K] <TensorType(int64, vector)> ''   \n | |   |Shape_i{0} [id L] <TensorType(int64, scalar)> ''   \n | |   | |df_ph [id J] <TensorType(float32, 4D)>\n | |   |TensorConstant{-1} [id H] <TensorType(int64, scalar)>\n | |Reshape{2} [id M] <TensorType(float32, matrix)> ''   \n |   |dt_ph [id N] <TensorType(float32, 4D)>\n |   |MakeVector{dtype='int64'} [id O] <TensorType(int64, vector)> ''   \n |     |Shape_i{0} [id P] <TensorType(int64, scalar)> ''   \n |     | |dt_ph [id N] <TensorType(float32, 4D)>\n |     |TensorConstant{-1} [id H] <TensorType(int64, scalar)>\n |W [id Q] <TensorType(float32, matrix)>\n\nStorage map footprint:\n - W, Shared Input, Shape: (30750, 8200), ElemSize: 4 Byte(s), TotalSize: 1008600000 Byte(s)\n - <TensorType(float32, matrix)>, Shared Input, Shape: (30750, 8200), ElemSize: 4 Byte(s), TotalSize: 1008600000 Byte(s)\n - <TensorType(float32, matrix)>, Shared Input, Shape: (30750, 8200), ElemSize: 4 Byte(s), TotalSize: 1008600000 Byte(s)\n - targets, Input, Shape: (2, 8, 11, 1025), ElemSize: 4 Byte(s), TotalSize: 721600 Byte(s)\n - Join.0, Shape: (2, 67650), ElemSize: 4 Byte(s), TotalSize: 541200 Byte(s)\n - amp, Input, Shape: (2, 2, 11, 1025), ElemSize: 4 Byte(s), TotalSize: 180400 Byte(s)\n - dt_ph, Input, Shape: (2, 2, 11, 1025), ElemSize: 4 Byte(s), TotalSize: 180400 Byte(s)\n - df_ph, Input, Shape: (2, 2, 11, 1025), ElemSize: 4 Byte(s), TotalSize: 180400 Byte(s)\n - b, Shared Input, Shape: (8200,), ElemSize: 4 Byte(s), TotalSize: 32800 Byte(s)\n - <TensorType(float32, vector)>, Shared Input, Shape: (8200,), ElemSize: 4 Byte(s), TotalSize: 32800 Byte(s)\n - <TensorType(float32, vector)>, Shared Input, Shape: (8200,), ElemSize: 4 Byte(s), TotalSize: 32800 Byte(s)\n - TensorConstant{[   2    8 1025]}, Shape: (3,), ElemSize: 8 Byte(s), TotalSize: 24 Byte(s)\n - Shape_i{0}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Constant{5}, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - TensorConstant{-1}, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - TensorConstant{6.097561e-05}, Shape: (), ElemSize: 4 Byte(s), TotalSize: 4.0 Byte(s)\n - TensorConstant{(1,) of 0.95}, Shape: (1,), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - TensorConstant{(1, 1) of ...050000012}, Shape: (1, 1), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - TensorConstant{(1,) of 1e-06}, Shape: (1,), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - TensorConstant{(1,) of 0.050000012}, Shape: (1,), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - TensorConstant{(1, 1) of 0.95}, Shape: (1, 1), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - TensorConstant{(1, 1) of 0.5}, Shape: (1, 1), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - TensorConstant{(1, 1) of 1e-06}, Shape: (1, 1), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - TensorConstant{(1, 1, 1) ..0012195122}, Shape: (1, 1, 1), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - TensorConstant{1}, Shape: (), ElemSize: 1 Byte(s), TotalSize: 1.0 Byte(s)\n TotalSize: 3027702485.0 Byte(s) 2.820 GB\n TotalSize inputs: 3027161277.0 Byte(s) 2.819 GB\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m~/.pyenv/versions/3.5.6/lib/python3.5/site-packages/theano/compile/function_module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    902\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 903\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0moutput_subset\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    904\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Shape mismatch: x has 67650 cols (and 2 rows) but y has 30750 rows (and 8200 cols)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-20874e928064>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0mdt_ph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_ph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdt_ph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmag\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m             \u001b[0merrs\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_ph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdt_ph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m             \u001b[0mtrain_batches\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.5.6/lib/python3.5/site-packages/theano/compile/function_module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    915\u001b[0m                     \u001b[0mnode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mposition_of_error\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m                     \u001b[0mthunk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mthunk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m                     storage_map=getattr(self.fn, 'storage_map', None))\n\u001b[0m\u001b[1;32m    918\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m                 \u001b[0;31m# old-style linkers raise their own exceptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.5.6/lib/python3.5/site-packages/theano/gof/link.py\u001b[0m in \u001b[0;36mraise_with_op\u001b[0;34m(node, thunk, exc_info, storage_map)\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0;31m# extra long error message in that case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m         \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m     \u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_trace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.5.6/lib/python3.5/site-packages/six.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(tp, value, tb)\u001b[0m\n\u001b[1;32m    690\u001b[0m                 \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 692\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    693\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    694\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.5.6/lib/python3.5/site-packages/theano/compile/function_module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    901\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 903\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0moutput_subset\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    904\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    905\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Shape mismatch: x has 67650 cols (and 2 rows) but y has 30750 rows (and 8200 cols)\nApply node that caused the error: Dot22(Join.0, W)\nToposort index: 16\nInputs types: [TensorType(float32, matrix), TensorType(float32, matrix)]\nInputs shapes: [(2, 67650), (30750, 8200)]\nInputs strides: [(270600, 4), (32800, 4)]\nInputs values: ['not shown', 'not shown']\nInputs type_num: [11, 11]\nOutputs clients: [[Elemwise{Add}[(0, 0)](Dot22.0, InplaceDimShuffle{x,0}.0)]]\n\nBacktrace when the node is created(use Theano flag traceback.limit=N to make it longer):\n  File \"/home/pierre-louis/.pyenv/versions/3.5.6/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2869, in _run_cell\n    return runner(coro)\n  File \"/home/pierre-louis/.pyenv/versions/3.5.6/lib/python3.5/site-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/home/pierre-louis/.pyenv/versions/3.5.6/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 3044, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/pierre-louis/.pyenv/versions/3.5.6/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 3209, in run_ast_nodes\n    if (yield from self.run_code(code, result)):\n  File \"/home/pierre-louis/.pyenv/versions/3.5.6/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 3291, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-3-41a522242940>\", line 24, in <module>\n    prediction = lasagne.layers.get_output(network, deterministic=True)\n  File \"/home/pierre-louis/.pyenv/versions/3.5.6/lib/python3.5/site-packages/lasagne/layers/helper.py\", line 197, in get_output\n    all_outputs[layer] = layer.get_output_for(layer_inputs, **kwargs)\n  File \"/home/pierre-louis/.pyenv/versions/3.5.6/lib/python3.5/site-packages/lasagne/layers/dense.py\", line 121, in get_output_for\n    activation = T.dot(input, self.W)\n\nDebugprint of the apply node: \nDot22 [id A] <TensorType(float32, matrix)> ''   \n |Join [id B] <TensorType(float32, matrix)> ''   \n | |TensorConstant{1} [id C] <TensorType(int8, scalar)>\n | |Reshape{2} [id D] <TensorType(float32, matrix)> ''   \n | | |amp [id E] <TensorType(float32, 4D)>\n | | |MakeVector{dtype='int64'} [id F] <TensorType(int64, vector)> ''   \n | |   |Shape_i{0} [id G] <TensorType(int64, scalar)> ''   \n | |   | |amp [id E] <TensorType(float32, 4D)>\n | |   |TensorConstant{-1} [id H] <TensorType(int64, scalar)>\n | |Reshape{2} [id I] <TensorType(float32, matrix)> ''   \n | | |df_ph [id J] <TensorType(float32, 4D)>\n | | |MakeVector{dtype='int64'} [id K] <TensorType(int64, vector)> ''   \n | |   |Shape_i{0} [id L] <TensorType(int64, scalar)> ''   \n | |   | |df_ph [id J] <TensorType(float32, 4D)>\n | |   |TensorConstant{-1} [id H] <TensorType(int64, scalar)>\n | |Reshape{2} [id M] <TensorType(float32, matrix)> ''   \n |   |dt_ph [id N] <TensorType(float32, 4D)>\n |   |MakeVector{dtype='int64'} [id O] <TensorType(int64, vector)> ''   \n |     |Shape_i{0} [id P] <TensorType(int64, scalar)> ''   \n |     | |dt_ph [id N] <TensorType(float32, 4D)>\n |     |TensorConstant{-1} [id H] <TensorType(int64, scalar)>\n |W [id Q] <TensorType(float32, matrix)>\n\nStorage map footprint:\n - W, Shared Input, Shape: (30750, 8200), ElemSize: 4 Byte(s), TotalSize: 1008600000 Byte(s)\n - <TensorType(float32, matrix)>, Shared Input, Shape: (30750, 8200), ElemSize: 4 Byte(s), TotalSize: 1008600000 Byte(s)\n - <TensorType(float32, matrix)>, Shared Input, Shape: (30750, 8200), ElemSize: 4 Byte(s), TotalSize: 1008600000 Byte(s)\n - targets, Input, Shape: (2, 8, 11, 1025), ElemSize: 4 Byte(s), TotalSize: 721600 Byte(s)\n - Join.0, Shape: (2, 67650), ElemSize: 4 Byte(s), TotalSize: 541200 Byte(s)\n - amp, Input, Shape: (2, 2, 11, 1025), ElemSize: 4 Byte(s), TotalSize: 180400 Byte(s)\n - dt_ph, Input, Shape: (2, 2, 11, 1025), ElemSize: 4 Byte(s), TotalSize: 180400 Byte(s)\n - df_ph, Input, Shape: (2, 2, 11, 1025), ElemSize: 4 Byte(s), TotalSize: 180400 Byte(s)\n - b, Shared Input, Shape: (8200,), ElemSize: 4 Byte(s), TotalSize: 32800 Byte(s)\n - <TensorType(float32, vector)>, Shared Input, Shape: (8200,), ElemSize: 4 Byte(s), TotalSize: 32800 Byte(s)\n - <TensorType(float32, vector)>, Shared Input, Shape: (8200,), ElemSize: 4 Byte(s), TotalSize: 32800 Byte(s)\n - TensorConstant{[   2    8 1025]}, Shape: (3,), ElemSize: 8 Byte(s), TotalSize: 24 Byte(s)\n - Shape_i{0}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Constant{5}, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - TensorConstant{-1}, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - TensorConstant{6.097561e-05}, Shape: (), ElemSize: 4 Byte(s), TotalSize: 4.0 Byte(s)\n - TensorConstant{(1,) of 0.95}, Shape: (1,), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - TensorConstant{(1, 1) of ...050000012}, Shape: (1, 1), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - TensorConstant{(1,) of 1e-06}, Shape: (1,), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - TensorConstant{(1,) of 0.050000012}, Shape: (1,), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - TensorConstant{(1, 1) of 0.95}, Shape: (1, 1), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - TensorConstant{(1, 1) of 0.5}, Shape: (1, 1), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - TensorConstant{(1, 1) of 1e-06}, Shape: (1, 1), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - TensorConstant{(1, 1, 1) ..0012195122}, Shape: (1, 1, 1), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - TensorConstant{1}, Shape: (), ElemSize: 1 Byte(s), TotalSize: 1.0 Byte(s)\n TotalSize: 3027702485.0 Byte(s) 2.820 GB\n TotalSize inputs: 3027161277.0 Byte(s) 2.819 GB\n\n"
     ]
    }
   ],
   "source": [
    "theano.config.exception_verbosity = \"high\"\n",
    "\n",
    "if not skip_train:\n",
    "#     for epoch in range(num_epochs):\n",
    "#         train_err = 0\n",
    "#         train_batches = 0\n",
    "#         errs = np.zeros((nchannels,nsources))\n",
    "#         start_time = time.time()\n",
    "#         for batch in range(train.iteration_size):\n",
    "#             mag, target, features = train()\n",
    "#             df_ph, dt_ph = features[..., :]\n",
    "#             train_err += train_fn_mse(mag, target)\n",
    "#             errs += np.array(train_fn1(mag, df_ph, dt_ph, target))\n",
    "#             train_batches += 1\n",
    "\n",
    "#         logging.info(\"Epoch {} of {} took {:.3f}s\".format(\n",
    "#             epoch + 1, num_epochs, time.time() - start_time))\n",
    "#         logging.info(\"  training loss:\\t\\t{:.6f}\".format(train_err/train_batches))\n",
    "#         for j in range(nchannels):\n",
    "#             for i in range(nsources):\n",
    "#                 logging.info(\"  training loss for \"+sources[i]+\" in mic \"+str(j)+\":\\t\\t{:.6f}\".format(errs[j][i]/train_batches))\n",
    "\n",
    "#         model_noILD = model[:-4] + '_noILD' + model[-4:]\n",
    "#         print('model_noILD: ', model_noILD)\n",
    "#         save_model(model_noILD,network)\n",
    "#         losser.append(train_err/train_batches)\n",
    "        \n",
    "        \n",
    "    for epoch in range(num_epochs):\n",
    "        # In each epoch, we do a full pass over the training data:\n",
    "        train_err = 0\n",
    "        train_batches = 0\n",
    "        start_time = time.time()\n",
    "        errs = np.zeros((nchannels,nsources))\n",
    "        for batch in range(train.iteration_size):\n",
    "            mag, target, features = train()\n",
    "            df_ph = features[..., 0]\n",
    "            dt_ph = features[..., 1]\n",
    "            print(df_ph.shape, dt_ph.shape, mag.shape, target.shape)\n",
    "            errs += np.array(train_fn(mag, df_ph, dt_ph, target))\n",
    "            train_batches += 1\n",
    "\n",
    "\n",
    "        # And a full pass over the validation data:\n",
    "#         val_err = 0\n",
    "#         val_acc = 0\n",
    "#         val_batches = 0\n",
    "#         for batch in iterate_minibatches(X_val, y_val, 500, shuffle=False):\n",
    "#             inputs, targets = batch\n",
    "#             err, acc = val_fn(inputs, targets)\n",
    "#             val_err += err\n",
    "#             val_acc += acc\n",
    "#             val_batches += 1\n",
    "\n",
    "        # Then we print the results for this epoch:\n",
    "        print(\"Epoch {} of {} took {:.3f}s\".format(\n",
    "            epoch + 1, num_epochs, time.time() - start_time))\n",
    "        print(\"  training loss:\\t\\t{:.6f}\".format(err / train_batches))\n",
    "#         print(\"  training loss:\\t\\t{:.6f}\".format(train_err / train_batches))\n",
    "#         print(\"  validation loss:\\t\\t{:.6f}\".format(val_err / val_batches))\n",
    "#         print(\"  validation accuracy:\\t\\t{:.2f} %\".format(\n",
    "#             val_acc / val_batches * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs, targets, features = train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_fn(mag, df_ph, dt_ph, target)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
